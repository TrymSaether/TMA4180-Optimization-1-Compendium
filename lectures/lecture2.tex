\subsubsection{Lecture 2 (10. January 2025)}

\section*{Gradientmetoder og konveksitet}

\begin{theorem}{Gradientestimat nær lokale minima}{gradient-estimate}
    La $f: \mathbb{R}^n \to \mathbb{R}$ være deriverbar og $x^*$ være et lokalt minimum. Da gjelder:
    \[
        \|\nabla f(x)\| \to 0 \quad \text{når } x \to x^*.
    \]
\end{theorem}

\begin{remark}{Geometrisk tolkning}
    Dette indikerer at funksjonen blir "flatere" når $x$ nærmer seg minimumpunktet, noe som er fundamentalt for konvergensen til iterative optimaliseringsmetoder.
\end{remark}

\begin{definition}{Konveks funksjon}{convex-function}
    En funksjon $f: \mathbb{R}^n \to \mathbb{R}$ er konveks hvis, for alle $x, y \in \mathbb{R}^n$ og $\lambda \in (0,1)$:
    \begin{align*}
        f(\lambda x + (1 - \lambda)y) \leq \lambda f(x) + (1 - \lambda)f(y) \tag{Konveks} \\
        f(\lambda x + (1 - \lambda)y) < \lambda f(x) + (1 - \lambda)f(y) \tag{Strengt konveks}
    \end{align*}

\end{definition}

\begin{theorem}{Karakterisering av deriverbare konvekse funksjoner}{convex-characterization}
    For en deriverbar funksjon $f: \mathbb{R}^n \to \mathbb{R}$ er følgende ekvivalente:
    \begin{itemize}
        \item $f$ er konveks
        \item For alle $x, y \in \mathbb{R}^n$ gjelder:
              \[
                  f(y) \geq f(x) + \nabla f(x)^\top (y - x)
              \]
    \end{itemize}
\end{theorem}

\begin{theorem}{Karakterisering av konvekse funksjoner med Hessian}{convex-hessian}
    For en dobbelt deriverbar funksjon $f: \mathbb{R}^n \to \mathbb{R}$ er følgende ekvivalente:
    \[
        f \text{ er konveks} \iff H_f(x) \succeq 0 \quad \forall x \in \mathbb{R}^n
    \]

    $H_f(x) \succeq 0$ betyr at Hessian-matrisen er positiv semi-definit for alle $x$.

\end{theorem}

\begin{remark}{Positiv semi-definit matrise}
    En matrise $A \in \mathbb{R}^{n \times n}$ er positiv semi-definit hvis og bare hvis en av følgende ekvivalente påstander holder:
    \begin{align*}
        A \succeq 0 & \iff x^\top A x \geq 0 \quad \forall x \in \mathbb{R}^n \tag{Kvadratisk form}                     \\
                    & \iff \lambda_i \geq 0 \text{ for alle egenverdier } \lambda_i \text{ av } A \tag{Egenverdier}     \\
                    & \iff \text{Alle hovedminordeterminanter er ikke-negative} \tag{Minordeterminanter}                \\
                    & \iff A = LL^\top \text{ for en nedre triangulær matrise } L \tag{Cholesky}                        \\
                    & \iff A = B^\top B \text{ for en matrise } B \in \mathbb{R}^{m \times n} \tag{Gram}                \\
                    & \iff A - 0 \cdot I \succeq 0 \tag{Semidefinit ordning}                                            \\
                    & \iff A \text{ ligger i den positive semidefinite konen i } \mathbb{R}^{n \times n} \tag{PSD kone} \\
                    & \iff e^{tA} \text{ er positiv semidefinit for alle } t > 0 \tag{Matrise eksponential}
    \end{align*}

    \begin{itemize}
        \item Kvadratisk form: $x^\top A x \geq 0$ for alle $x \in \mathbb{R}^n$ karakteriserer positiv semi-definite matriser.
        \item Egenverdier: Alle egenverdier $\lambda_i$ av $A$ er ikke-negative.
        \item Hovedminordeterminant: Determinanten til alle hoved-undermatriser er ikke-negative.
              \[
              \begin{bmatrix}
                      a_{11} & a_{12} \\
                      a_{21} & a_{22}
                  \end{bmatrix} \succeq 0 \iff a_{11} \geq 0, \quad a_{11}a_{22} - a_{12}a_{21} \geq 0
                  \]

        \item Cholesky-faktorisering: $A = LL^\top$ der $L$ er en nedre triangulær matrise.
        \item Gram-matrise: $A = B^\top B$ der $B \in \mathbb{R}^{m \times n}$.
        \item Semidefinit ordning: $A - 0 \cdot I \succeq 0$ betyr at $A$ er positiv semi-definit.
        \item PSD-kone: Den positive semidefinite konen er mengden av alle positiv semi-definite matriser.
        \item Matrise eksponential: $e^{tA}$ er positiv semi-definit for alle $t > 0$.
    \end{itemize}
\end{remark}


\begin{theorem}{Globale egenskaper for konvekse funksjoner}{global-properties}
    La $f: \mathbb{R}^n \to \mathbb{R}$ være konveks. Da gjelder:
    \begin{itemize}
        \item Ethvert lokalt minimum er også et globalt minimum.
        \item Hvis $\nabla f(x^*) = 0$, da er $x^*$ et globalt minimum.
    \end{itemize}
\end{theorem}

\begin{example}{Konvekse funksjoner}{convex-examples}
    Noen klassiske eksempler på konvekse funksjoner:
    \begin{itemize}
        \item Lineære funksjoner: $f(x) = a^\top x + b$
        \item Kvadratiske funksjoner med positiv definit matrise: $f(x) = x^\top Ax + b^\top x + c$, der $A \succ 0$
        \item Eksponentialfunksjonen: $f(x) = e^{ax}$ for enhver $a \in \mathbb{R}$
    \end{itemize}
\end{example}