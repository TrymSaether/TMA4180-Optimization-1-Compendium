\chapter{Introduksjon til Betinget Optimering}

Betinget optimering handler om å finne de optimale verdiene for en funksjon under gitte restriksjoner.

\section{Problemformulering}

Et generelt betinget optimeringsproblem kan skrives som:
\begin{mini*}
	{x \in \mathbb{R}^n}{f(x)}{}{}
	\addConstraint{g_i(x)}{\leq 0,\quad}{ i = 1,\ldots,m}
	\addConstraint{h_j(x)}{= 0,\quad}{ j = 1,\ldots,p}
\end{mini*}

Her betyr:
\begin{itemize}
	\item $f(x)$: Målfunksjonen som skal minimeres.
	\item $g_i(x)$: Ulikhetsbetingelser som setter øvre grenser.
	\item $h_j(x)$: Likhetsbetingelser som må oppfylles nøyaktig.
\end{itemize}

Disse restriksjonene definerer området, $\Omega$, der løsningen må ligge.

\subsection{Lineært Betinget Optimeringsproblem}

\begin{definition}{Lineært optimeringsproblem}{linear_programming}
	Et lineært optimeringsproblem har formen:
	\begin{mini*}
		{x\in\R^n}{c^Tx}{}{}
		\addConstraint{Ax}{\leq b,}{}
		\addConstraint{Dx}{= e,}{}
	\end{mini*}
	Her er:
	\begin{itemize}
		\item \(c \in \R^n\): Kostnadsvektor.
		\item \(A \in \R^{m \times n}\): Matrise for ulikhetsbetingelsene.
		\item \(D \in \R^{p \times n}\): Matrise for likhetsbetingelsene.
		\item \(b \in \R^m\) og \(e \in \R^p\): Vektorer med høyre siden-verdier.
	\end{itemize}
\end{definition}

\begin{example}{Lineær funksjon}{linear_function}
	La \(f(\symbf{x}) = c^T\symbf{x} + d\) være en lineær funksjon, hvor \(c\) er en vektor normal til en hyperplan og \(d\) er en konstant. Likningen \(f(\symbf{x}) = 0\) definerer da et hyperplan i \(\R^n\).
\end{example}

\begin{example}{Lineær regresjon}{linear_regression}
	Anta at \(X \in \R^{n \times m}\) representerer observasjonsdata og \(y \in \R^n\) representerer måledata. Lineær regresjon kan sees som et lineært optimeringsproblem der vi ønsker å finne vektoren \(w \in \R^m\) som minimerer kvadratavviket:
	\begin{equation*}
		\min_{w \in \R^m} \norm{Xw - y}_2^2.
	\end{equation*}
\end{example}

\section{Typer Betingelser}

\subsection{Likhetsbetingelser}
Likhetsbetingelser krever at funksjonen oppfyller en eksakt verdi:
\begin{equation*}
	h_j(x) = 0, \quad j = 1,\ldots,p.
\end{equation*}

Geometrisk representerer hver likhetsbetingelse et hyperplan (en \((n-1)\)-dimensjonal flate) i $\mathbb{R}^n$. For å være i $\Omega$ må punktet ligge på skjæringspunktet av alle slike flater.

\subsection{Ulikhetsbetingelser}
Ulikhetsbetingelser krever at funksjonen ikke overskrider en grense:
\begin{equation*}
	g_i(x) \leq 0, \quad i = 1,\ldots,m.
\end{equation*}

Hver ulikhetsbetingelse definerer et halvrom i $\mathbb{R}^n$. Et punkt er gyldig dersom det ligger i snittet av alle disse halvrommene. En betingelse $g_i(x) \leq 0$ sies å være aktiv ved et punkt $x^*$ hvis $g_i(x^*) = 0$; ellers er den inaktiv.

\section{Tillatt Område og Retninger}

\subsection{Tillatt Område}
Det tillatte området, kalt \(\Omega\), består av alle punktene som oppfyller restriksjonene:
\begin{equation*}
	\Omega = \{x \in \mathbb{R}^n \mid g_i(x) \leq 0,\ i = 1,\ldots,m, \text{ og } h_j(x) = 0,\ j = 1,\ldots,p\}.
\end{equation*}

\subsection{Tillatte Retninger}
Ved et punkt \(x \in \Omega\) er en retning \(d \in \mathbb{R}^n\) tillatt hvis det finnes et \(t > 0\) slik at \(x + \alpha d \in \Omega\) for alle \(\alpha \in (0, t]\). For glatte restriksjoner kan vi bruke gradienter til å verifisere dette:
\begin{equation*}
	\nabla g_i(x)^T d \leq 0 \quad \text{for alle aktive } g_i,
\end{equation*}
\begin{equation*}
	\nabla h_j(x)^T d = 0 \quad \text{for alle } h_j.
\end{equation*}

\section{Tangent- og Normalkjegle}

\subsection{Tangetkjegle}
Tangetkjeglen \(T_{\Omega}(x)\) ved et punkt \(x \in \Omega\) er mengden av alle retninger som kan beskrives som:
\begin{equation*}
	T_{\Omega}(x) = \{d \in \mathbb{R}^n \mid \nabla g_i(x)^T d \leq 0 \text{ for alle aktive } g_i,\ \nabla h_j(x)^T d = 0 \text{ for alle } h_j\}.
\end{equation*}
Dette representerer alle mulige bevegelser innenfor \(\Omega\) fra punktet \(x\).

\subsection{Normalkjegle}
Normalkjeglen \(N_{\Omega}(x)\) er definert som mengden av vektorer som er ortogonale til alle retninger i tangetkjeglen:
\begin{equation*}
	N_{\Omega}(x) = \{v \in \mathbb{R}^n \mid v^T d \leq 0 \text{ for alle } d \in T_{\Omega}(x)\}.
\end{equation*}

Under forutsetning av LICQ (Linear Independence Constraint Qualification) kan normalkjeglen uttrykkes som:
\begin{equation*}
	N_{\Omega}(x) = \left\{\sum_{i \in I(x)} \lambda_i \nabla g_i(x) + \sum_{j=1}^p \mu_j \nabla h_j(x) \mid \lambda_i \geq 0 \right\},
\end{equation*}
hvor \(I(x) = \{i \mid g_i(x) = 0\}\) er indeksen til de aktive ulikhetsbetingelsene.

Både tangent- og normalkjegle er viktige for å formulere de første ordens nødvendige betingelsene (KKT-betingelsene) som skal diskuteres i neste kapittel.
