\chapter{Theory of Convex Optimization}

\section{Slater's Constraint Qualification}

Slater's constraint qualification is a condition that ensures strong duality holds in convex optimization problems.

\begin{definition}{Slater's Condition}{slaters_condition}
    For a convex optimization problem:
    \begin{mini*}
        {x}{f(x)}{}{}
        \addConstraint{g_i(x)}{\leq 0,\quad}{i = 1, \ldots, m}
        \addConstraint{Ax}{= b}{}
    \end{mini*}
    where $f$ and $g_i$ are convex, Slater's condition holds if there exists a point $\bar{x}$ such that:
    \begin{itemize}
        \item $g_i(\bar{x}) < 0$ for all $i = 1, \ldots, m$
        \item $A\bar{x} = b$
    \end{itemize}
    This point $\bar{x}$ is called a strictly feasible point.
\end{definition}

\begin{theorem}{Importance of Slater's Condition}{slater_importance}
    For a convex optimization problem that satisfies Slater's condition:
    \begin{enumerate}
        \item Strong duality holds: the optimal values of the primal and dual problems are equal
        \item If the primal optimal value is finite, the dual optimal value is attained
        \item The KKT conditions are necessary and sufficient for optimality
    \end{enumerate}
\end{theorem}

\section{Farkas' Lemma}

Farkas' Lemma is a fundamental result in convex analysis and optimization that characterizes when a linear inequality is a consequence of a system of linear inequalities.

\begin{lemma}{Farkas' Lemma}{farkas_lemma}
    Let $A \in \mathbb{R}^{m \times n}$ and $c \in \mathbb{R}^n$. Then, exactly one of the following two statements is true:
    \begin{enumerate}
        \item There exists an $x \in \mathbb{R}^n$ such that $Ax \leq 0$ and $c^Tx > 0$.
        \item There exists a $y \in \mathbb{R}^m$ such that $y \geq 0$ and $A^Ty = c$.
    \end{enumerate}
\end{lemma}

Farkas' Lemma is often used to establish the existence of Lagrange multipliers and to derive duality results in optimization.

\section{Lagrangian Function}

The Lagrangian function combines the objective function with constraint functions through Lagrange multipliers.

\begin{definition}{Lagrangian Function}{lagrangian}
    For the constrained optimization problem:
    \begin{mini*}
        {x}{f(x)}{}{}
        \addConstraint{g_i(x)}{\leq 0,\quad}{i = 1, \ldots, m}
        \addConstraint{h_j(x)}{= 0,\quad}{j = 1, \ldots, p}
    \end{mini*}
    The Lagrangian function is defined as:
    \[
    \mathcal{L}(x, \lambda, \mu) = f(x) + \sum_{i=1}^m \lambda_i g_i(x) + \sum_{j=1}^p \mu_j h_j(x)
    \]
    where $\lambda \in \mathbb{R}^m$ with $\lambda \geq 0$ and $\mu \in \mathbb{R}^p$ are the Lagrange multipliers.
\end{definition}

The Lagrangian function plays a central role in constrained optimization, forming the basis for KKT conditions and duality theory.

\section{KKT Conditions for Convex Problems}

The Karush-Kuhn-Tucker (KKT) conditions are necessary and sufficient conditions for optimality in convex optimization problems.

\begin{theorem}{KKT Conditions for Convex Problems}{kkt_convex}
    Consider a convex optimization problem where $f$ and $g_i$ are convex, and $h_j$ are affine. Suppose that Slater's condition is satisfied. Then $x^*$ is an optimal solution if and only if there exist Lagrange multipliers $\lambda^* \in \mathbb{R}^m$ and $\mu^* \in \mathbb{R}^p$ such that:
    \begin{align}
        \nabla f(x^*) + \sum_{i=1}^m \lambda_i^* \nabla g_i(x^*) + \sum_{j=1}^p \mu_j^* \nabla h_j(x^*) &= 0 \tag{Stationarity}\\
        g_i(x^*) &\leq 0, \quad \forall i = 1, \ldots, m \tag{Primal Feasibility}\\
        h_j(x^*) &= 0, \quad \forall j = 1, \ldots, p \tag{Primal Feasibility}\\
        \lambda_i^* &\geq 0, \quad \forall i = 1, \ldots, m \tag{Dual Feasibility}\\
        \lambda_i^* g_i(x^*) &= 0, \quad \forall i = 1, \ldots, m \tag{Complementary Slackness}
    \end{align}
\end{theorem}

\section{Duality in Convex Optimization}

\subsection{Weak and Strong Duality}

\begin{definition}{Dual Function}{dual_function}
    The dual function $g: \mathbb{R}^m \times \mathbb{R}^p \to \mathbb{R}$ is defined as:
    \[
    g(\lambda, \mu) = \inf_{x \in \mathbb{R}^n} \mathcal{L}(x, \lambda, \mu)
    \]
\end{definition}

\begin{definition}{Dual Problem}{dual_problem}
    The dual problem is:
    \begin{maxi*}
        {\lambda \geq 0, \mu}{g(\lambda, \mu)}{}{}
    \end{maxi*}
\end{definition}

\begin{theorem}{Weak Duality}{weak_duality}
    If $x$ is primal feasible and $(\lambda, \mu)$ is dual feasible with $\lambda \geq 0$, then:
    \[
    g(\lambda, \mu) \leq f(x)
    \]
    This means the optimal value of the dual problem is a lower bound on the optimal value of the primal problem.
\end{theorem}

\begin{theorem}{Strong Duality}{strong_duality}
    If the primal problem is convex and Slater's condition holds, then strong duality holds: the optimal values of the primal and dual problems are equal.
\end{theorem}

\subsection{Saddle Points}

\begin{definition}{Saddle Point}{saddle_point}
    A point $(x^*, \lambda^*, \mu^*)$ is a saddle point of the Lagrangian if:
    \[
    \mathcal{L}(x^*, \lambda, \mu) \leq \mathcal{L}(x^*, \lambda^*, \mu^*) \leq \mathcal{L}(x, \lambda^*, \mu^*)
    \]
    for all $x \in \mathbb{R}^n$, $\lambda \geq 0$, and $\mu \in \mathbb{R}^p$.
\end{definition}

\begin{theorem}{Saddle Point Theorem}{saddle_point_theorem}
    For a convex optimization problem, $(x^*, \lambda^*, \mu^*)$ is a saddle point of the Lagrangian if and only if:
    \begin{itemize}
        \item $x^*$ is primal optimal
        \item $(\lambda^*, \mu^*)$ is dual optimal
        \item Strong duality holds
    \end{itemize}
\end{theorem}

\subsection{Lagrangian Duality}

Lagrangian duality provides a systematic way to derive dual problems and establish duality results.

\begin{theorem}{Lagrangian Duality}{lagrangian_duality}
    For a convex optimization problem:
    \[
    \min_{x \in \mathbb{R}^n} f(x) = \min_{x \in \mathbb{R}^n} \max_{\lambda \geq 0, \mu} \mathcal{L}(x, \lambda, \mu)
    \]
    When strong duality holds:
    \[
    \min_{x \in \mathbb{R}^n} \max_{\lambda \geq 0, \mu} \mathcal{L}(x, \lambda, \mu) = \max_{\lambda \geq 0, \mu} \min_{x \in \mathbb{R}^n} \mathcal{L}(x, \lambda, \mu)
    \]
\end{theorem}

\subsection{Legendre-Fenchel Transform}

\begin{definition}{Legendre-Fenchel Transform}{legendre_fenchel}
    The Legendre-Fenchel transform (or convex conjugate) of a function $f: \mathbb{R}^n \to \mathbb{R} \cup \{+\infty\}$ is:
    \[
    f^*(y) = \sup_{x \in \mathbb{R}^n} \{y^Tx - f(x)\}
    \]
\end{definition}

\begin{theorem}{Properties of Legendre-Fenchel Transform}{legendre_fenchel_properties}
    The Legendre-Fenchel transform has several important properties:
    \begin{itemize}
        \item $f^*$ is always convex, even if $f$ is not
        \item If $f$ is convex and lower semicontinuous, then $(f^*)^* = f$
        \item If $f$ is strictly convex and differentiable, then $\nabla f^*(y) = x$ where $y = \nabla f(x)$
    \end{itemize}
\end{theorem}

The Legendre-Fenchel transform provides powerful tools for duality theory and convex analysis, connecting problems through their dual formulations.
